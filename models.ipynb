{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Collaborative filtering model\n",
    "\n",
    "In my solution I used User-Based Top-N Recommendation Algorithm. I identified the k most similar users (nearest neighbors) to the active user using Cosine similarity. Each user is treated as a vector in the m-dimensional item space and the similarities between the active user and other users are computed between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys, csv, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample \n",
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from pandas.io.json import json_normalize\n",
    "from random import randrange, sample\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build matrix\n",
    "\n",
    "Building user-artist space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'ThirtyMusic/entities'\n",
    "relations_dir = 'ThirtyMusic/relations'\n",
    "\n",
    "artists_path_csv = os.path.join(data_dir, 'persons.csv')\n",
    "sessions_path_csv = os.path.join(relations_dir, 'sessions_short.csv')\n",
    "\n",
    "artists = pd.read_csv(artists_path_csv, delimiter=';', header=0)\n",
    "artists = artists.set_index('ID')\n",
    "\n",
    "sessions = pd.read_csv(sessions_path_csv, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix where: *rows = users, columns = artists, values[i][j] = number of times user_i listened to artist_j in all the sessions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ArtistsID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>{'3': 2, '546': 2, '544': 2, '259773': 1, '315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>{'158286': 1, '13': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>{'40': 1, '20': 1, '15': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>{'40': 1, '29': 3, '11': 1, '65': 1, '74': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>{'38701': 4, '34577': 3, '74637': 3, '148559':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId                                          ArtistsID\n",
       "0       4  {'3': 2, '546': 2, '544': 2, '259773': 1, '315...\n",
       "1      14                             {'158286': 1, '13': 1}\n",
       "2      17                        {'40': 1, '20': 1, '15': 1}\n",
       "3      60  {'40': 1, '29': 3, '11': 1, '65': 1, '74': 1, ...\n",
       "4      81  {'38701': 4, '34577': 3, '74637': 3, '148559':..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sessions.sort_values(by='UserId')\n",
    "s.drop(columns=['Type', 'Timestamp', 'ID'], inplace = True)\n",
    "s.set_index('UserId', inplace = True)\n",
    "g = s.groupby(['UserId'])['ArtistsID'].apply(lambda x: [a.split(',') for a in x.tolist() if \\\n",
    "                                                     not pd.isna(a)]).reset_index()\n",
    "g['ArtistsID'] = g['ArtistsID'].apply(lambda x: Counter(list(chain(*x))))\n",
    "\n",
    "# Saving this dictionary for the embeddings model\n",
    "dictionary_data = g.to_dict()['ArtistsID']\n",
    "\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used only a piece of the dataset because the matrix didn't fit in the memory.\n",
    "\n",
    "\n",
    "A possible solution of this issue described in the end of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 23741)\n"
     ]
    }
   ],
   "source": [
    "g = g.head(10000) \n",
    "matrix = json_normalize(g['ArtistsID'])\n",
    "matrix.set_index(g['UserId'], inplace=True)\n",
    "matrix.fillna(0, inplace=True)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building indexes\n",
    "idx_to_artist = dict(enumerate(list(map(int, matrix.columns))))\n",
    "artist_to_idx = dict(zip(idx_to_artist.values(),idx_to_artist.keys()))\n",
    "idx_to_user = dict(enumerate(list(map(int,matrix.index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Testing of recommender systems is tricky - we need to recommend relevant artists but it's difficult to check if the recomendations are indeed relevant.\n",
    "\n",
    "I was deleting some sells of the user-artist matrix from top_6 most listened artists. It was done only for users who had listened to more than 10 different artists in order to not encounter with the cold start problem.\n",
    "\n",
    "After creating the model I will check if the sells that were deleted (relevant artists) are in the top 10 recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_idxs = []\n",
    "test_artist_idxs = []\n",
    "test_val = []\n",
    "\n",
    "def select_test(user, test_size, topk = 6, n_listened = 10):\n",
    "    rated_artists = user[user>0]\n",
    "    if rated_artists.shape[0] > n_listened and len(test_user_idxs) < test_size:\n",
    "        artist_ind_num = randrange(1,topk)\n",
    "        rated_artists.sort_values(ascending=False, inplace=True)\n",
    "        artist_idx = rated_artists.index[artist_ind_num]\n",
    "        test_user_idxs.append(int(user.name))\n",
    "        test_artist_idxs.append(int(artist_idx))\n",
    "        test_val.append(rated_artists.loc[artist_idx])\n",
    "        user[artist_idx] = 0\n",
    "    return user\n",
    "\n",
    "test_size = int(matrix.shape[0]*0.3)\n",
    "matrix = matrix.apply(lambda x: select_test(x, test_size = test_size), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data & calculating cosine similarity btw users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>UserId</th>\n",
       "      <th>4</th>\n",
       "      <th>14</th>\n",
       "      <th>17</th>\n",
       "      <th>60</th>\n",
       "      <th>81</th>\n",
       "      <th>84</th>\n",
       "      <th>88</th>\n",
       "      <th>92</th>\n",
       "      <th>98</th>\n",
       "      <th>101</th>\n",
       "      <th>...</th>\n",
       "      <th>39979</th>\n",
       "      <th>39987</th>\n",
       "      <th>39992</th>\n",
       "      <th>39998</th>\n",
       "      <th>39999</th>\n",
       "      <th>40002</th>\n",
       "      <th>40003</th>\n",
       "      <th>40005</th>\n",
       "      <th>40011</th>\n",
       "      <th>40013</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>0.050307</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "UserId  4      14        17        60     81        84        88        92     \\\n",
       "UserId                                                                          \n",
       "4         0.0    0.0  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "14        0.0    0.0  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "17        0.0    0.0  0.000000  0.471405    0.0  0.000000  0.000000  0.000000   \n",
       "60        0.0    0.0  0.471405  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "81        0.0    0.0  0.000000  0.000000    0.0  0.015394  0.050307  0.009455   \n",
       "\n",
       "UserId  98     101    ...  39979  39987  39992  39998  39999  40002  40003  \\\n",
       "UserId                ...                                                    \n",
       "4         0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "14        0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "17        0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "60        0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "81        0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "UserId  40005  40011  40013  \n",
       "UserId                       \n",
       "4         0.0    0.0    0.0  \n",
       "14        0.0    0.0    0.0  \n",
       "17        0.0    0.0    0.0  \n",
       "60        0.0    0.0    0.0  \n",
       "81        0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_matrix = scaler.fit_transform(matrix)\n",
    "cosine_sim = cosine_similarity(scaled_matrix)\n",
    "np.fill_diagonal(cosine_sim, 0)\n",
    "cosine_sim = pd.DataFrame(cosine_sim, index=matrix.index, columns = matrix.index)\n",
    "cosine_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>top3</th>\n",
       "      <th>top4</th>\n",
       "      <th>top5</th>\n",
       "      <th>top6</th>\n",
       "      <th>top7</th>\n",
       "      <th>top8</th>\n",
       "      <th>top9</th>\n",
       "      <th>top10</th>\n",
       "      <th>...</th>\n",
       "      <th>top21</th>\n",
       "      <th>top22</th>\n",
       "      <th>top23</th>\n",
       "      <th>top24</th>\n",
       "      <th>top25</th>\n",
       "      <th>top26</th>\n",
       "      <th>top27</th>\n",
       "      <th>top28</th>\n",
       "      <th>top29</th>\n",
       "      <th>top30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35892</td>\n",
       "      <td>29866</td>\n",
       "      <td>18754</td>\n",
       "      <td>38902</td>\n",
       "      <td>36711</td>\n",
       "      <td>30011</td>\n",
       "      <td>28861</td>\n",
       "      <td>31195</td>\n",
       "      <td>667</td>\n",
       "      <td>38907</td>\n",
       "      <td>...</td>\n",
       "      <td>15029</td>\n",
       "      <td>17049</td>\n",
       "      <td>35680</td>\n",
       "      <td>24469</td>\n",
       "      <td>13855</td>\n",
       "      <td>36954</td>\n",
       "      <td>23558</td>\n",
       "      <td>17341</td>\n",
       "      <td>12516</td>\n",
       "      <td>8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40013</td>\n",
       "      <td>13194</td>\n",
       "      <td>13221</td>\n",
       "      <td>13218</td>\n",
       "      <td>13213</td>\n",
       "      <td>13209</td>\n",
       "      <td>13205</td>\n",
       "      <td>13202</td>\n",
       "      <td>13196</td>\n",
       "      <td>13185</td>\n",
       "      <td>...</td>\n",
       "      <td>13563</td>\n",
       "      <td>13268</td>\n",
       "      <td>13285</td>\n",
       "      <td>13284</td>\n",
       "      <td>13282</td>\n",
       "      <td>13277</td>\n",
       "      <td>13273</td>\n",
       "      <td>13272</td>\n",
       "      <td>13269</td>\n",
       "      <td>13267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60</td>\n",
       "      <td>40013</td>\n",
       "      <td>13196</td>\n",
       "      <td>13227</td>\n",
       "      <td>13221</td>\n",
       "      <td>13218</td>\n",
       "      <td>13213</td>\n",
       "      <td>13209</td>\n",
       "      <td>13205</td>\n",
       "      <td>13202</td>\n",
       "      <td>...</td>\n",
       "      <td>13236</td>\n",
       "      <td>13163</td>\n",
       "      <td>13269</td>\n",
       "      <td>13290</td>\n",
       "      <td>13285</td>\n",
       "      <td>13284</td>\n",
       "      <td>13282</td>\n",
       "      <td>13277</td>\n",
       "      <td>13273</td>\n",
       "      <td>13272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>17</td>\n",
       "      <td>40013</td>\n",
       "      <td>13196</td>\n",
       "      <td>13227</td>\n",
       "      <td>13221</td>\n",
       "      <td>13218</td>\n",
       "      <td>13213</td>\n",
       "      <td>13209</td>\n",
       "      <td>13205</td>\n",
       "      <td>13202</td>\n",
       "      <td>...</td>\n",
       "      <td>13236</td>\n",
       "      <td>13163</td>\n",
       "      <td>13269</td>\n",
       "      <td>13290</td>\n",
       "      <td>13285</td>\n",
       "      <td>13284</td>\n",
       "      <td>13282</td>\n",
       "      <td>13277</td>\n",
       "      <td>13273</td>\n",
       "      <td>13272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10727</td>\n",
       "      <td>13399</td>\n",
       "      <td>18834</td>\n",
       "      <td>26000</td>\n",
       "      <td>20035</td>\n",
       "      <td>24109</td>\n",
       "      <td>15422</td>\n",
       "      <td>8801</td>\n",
       "      <td>19141</td>\n",
       "      <td>14930</td>\n",
       "      <td>...</td>\n",
       "      <td>6514</td>\n",
       "      <td>25035</td>\n",
       "      <td>30799</td>\n",
       "      <td>14771</td>\n",
       "      <td>22556</td>\n",
       "      <td>84</td>\n",
       "      <td>8121</td>\n",
       "      <td>2383</td>\n",
       "      <td>92</td>\n",
       "      <td>38159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         top1   top2   top3   top4   top5   top6   top7   top8   top9  top10  \\\n",
       "UserId                                                                         \n",
       "4       35892  29866  18754  38902  36711  30011  28861  31195    667  38907   \n",
       "14      40013  13194  13221  13218  13213  13209  13205  13202  13196  13185   \n",
       "17         60  40013  13196  13227  13221  13218  13213  13209  13205  13202   \n",
       "60         17  40013  13196  13227  13221  13218  13213  13209  13205  13202   \n",
       "81      10727  13399  18834  26000  20035  24109  15422   8801  19141  14930   \n",
       "\n",
       "        ...  top21  top22  top23  top24  top25  top26  top27  top28  top29  \\\n",
       "UserId  ...                                                                  \n",
       "4       ...  15029  17049  35680  24469  13855  36954  23558  17341  12516   \n",
       "14      ...  13563  13268  13285  13284  13282  13277  13273  13272  13269   \n",
       "17      ...  13236  13163  13269  13290  13285  13284  13282  13277  13273   \n",
       "60      ...  13236  13163  13269  13290  13285  13284  13282  13277  13273   \n",
       "81      ...   6514  25035  30799  14771  22556     84   8121   2383     92   \n",
       "\n",
       "        top30  \n",
       "UserId         \n",
       "4        8856  \n",
       "14      13267  \n",
       "17      13272  \n",
       "60      13272  \n",
       "81      38159  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding top 30 similar users for each user\n",
    "\n",
    "def find_n_neighbours(df, n):\n",
    "    order = np.argsort(df.values, axis=1)[:, :n]\n",
    "    df = df.apply(lambda x: pd.Series(x.sort_values(ascending=False)\n",
    "           .iloc[:n].index, \n",
    "          index=['top{}'.format(i) for i in range(1, n+1)]), axis=1)\n",
    "    return df\n",
    "\n",
    "sim_user_top_30 = find_n_neighbours(cosine_sim, 30)\n",
    "sim_user_top_30.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the k most similar users have been discovered, their corresponding rows in the user-artist matrix R are aggregated to identify a set of artists, listened by the group together with their frequency. With the set of artists we recommend the top-N most frequent items in C that the active user has not listened.\n",
    "\n",
    "The aggregation of the similar users is done according to the next formula (weighted sum):\n",
    "\n",
    "Let k similar users have cos_distances = [d1, d2, ..., dk]. Normalize theese distances with MinMax normalization and inverse them as 1-d. The bigger the cosin distance the less should be the coefficient. That's why after normalization we need to inverse. \n",
    "\n",
    "Normalised and inversed coef = [nd1, nd2, ..., ndk]. The closer a user to the target user the bigger will be the coeficient ndi.\n",
    "\n",
    "The aggregation:\n",
    "\n",
    "| user_id/artist_id | artist_id_1 | artist_id_2  |...  |artist_id_k  |\n",
    "| ------------- |-------------|-------------|-------------|-------------|\n",
    "| **id_1**          | val1_1      | val2_1      |...       |val_k_1       |\n",
    "| **id_2**          | val1_2      |   val2_2    |...        |val_k_2        |\n",
    "| **id_3**          | val1_3      |    val2_3   | ...        |val_k_3        |\n",
    "\n",
    "> *value_for_artist_1 = val1_1 * nd1 + val1_2 * nd2 + ... + val_k_1 * ndk*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "3747                                     30STM+&+Nearq\n",
       "4807                    50+Cent+feat.+Snoop+Dogg+&+Pre\n",
       "65988     Calle+13+&+Tuna+Bardos+UPR+Rio+Piedras-Choir\n",
       "129                                              Track\n",
       "4966                                          5+A+Seco\n",
       "3984                        %3CArtista+Desconhecido%3E\n",
       "108316                     Dead+Silence+Hides+My+Cries\n",
       "3165                                 2+Chainz+&+Future\n",
       "271162        Pendulum+&+Fresh+feat.+Spyda+&+Tenor+Fly\n",
       "3582                                               2PM\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_to_user(user_id, matrix, sim_users, artists, k = 10):\n",
    "    listened_artitsts = matrix.loc[user_id]\n",
    "    listened_artitsts = listened_artitsts[listened_artitsts > 0]\n",
    "    \n",
    "    knn = sim_users.loc[user_id].tolist()\n",
    "    \n",
    "    cos_distances = cosine_sim[knn].loc[user_id]\n",
    "    \n",
    "    # normalizing distances to make coefficients\n",
    "    norm_cos_distances = (cos_distances-cos_distances.min())/(cos_distances.max()-cos_distances.min())\n",
    "    coef = norm_cos_distances.apply(lambda x: 1-x).sort_index()\n",
    "    \n",
    "    knn_matrix = matrix.loc[knn]\n",
    "    knn_matrix.sort_index().mul(coef, axis=0)\n",
    "    top_artists = knn_matrix.sum()\n",
    "    top_artists = top_artists[top_artists > 0]\n",
    "    \n",
    "    # removing artists that user knows\n",
    "    consider_artists = list(set(top_artists.index) - set(listened_artitsts.index))\n",
    "    \n",
    "    top_artists = top_artists.loc[consider_artists].sort_values(ascending=False)[:k]\n",
    "    top_artists_ids = list(map(int, top_artists.index))\n",
    "    top_artists_names = artists.loc[top_artists_ids]['Name']\n",
    "    return top_artists, top_artists_names\n",
    " \n",
    "top_artists, top_artists_names = recommend_to_user(user_id = 4,\n",
    "                                                   matrix = matrix,\n",
    "                                                   sim_users = sim_user_top_30,\n",
    "                                                   artists = artists)\n",
    "\n",
    "top_artists_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Recommending for all the test samples and then ckecking if the relevant artist (the one we removed) is in the top_10 recommended. Calculetiong the avg between all test samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06524725274725275"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_CF_model(test_user_idxs, matrix, sim_user_top_30, artists, k = 10):\n",
    "    n_relevant = 0\n",
    "    for i, user_id in enumerate(test_user_idxs):\n",
    "        res, _ = recommend_to_user(user_id, matrix, sim_user_top_30, artists)\n",
    "        top_artists_ids = list(map(int, res.index))[:k]\n",
    "        if test_artist_idxs[i] in top_artists_ids:\n",
    "            n_relevant += 1\n",
    "    n_test_samples = len(test_user_idxs)\n",
    "    return n_relevant/n_test_samples\n",
    "\n",
    "test_CF_model(test_user_idxs, matrix, sim_user_top_30, artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Another solution would be to use sparse representation on the matrix because the majority of it's values are None. [Scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html)\n",
    "\n",
    "There was not enough time to implement such an approach. I expect it would increase the quality a lot because now only a piece of the dataset is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Samples for t-test\n",
    "test_samples = [sample(test_user_idxs,len(test_user_idxs)//10) for i in range(30)]\n",
    "CF_model_sample = [test_CF_model(sample, matrix, sim_user_top_30, artists) for sample in test_samples]\n",
    "print(len(CF_model_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "I was building embeddings of users and artists such as:\n",
    "\n",
    "* user and artist are close in the embeddings space if the user likes the artist\n",
    "\n",
    "Due to transitivity from the first:\n",
    "* users are close together in the embeddings space if they are similar\n",
    "* artists are close together in the embeddings space if they are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build sample\n",
    "\n",
    "Sample cosisits of rows: user_id, artist_id, target\n",
    "\n",
    "If the user have listened to the artists target = 1, otherwise target = -1.\n",
    "\n",
    "* Negative samples were selected randomly from the artists that the user did not listened.\n",
    "* Positive samples were taken from the most listened artists by this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(session_dict, all_artist_ids, negative = 1e-5, positive = 0.1):\n",
    "    sample = []\n",
    "    start_time = 0\n",
    "    for i, (user, session) in enumerate(session_dict.items()):\n",
    "        factor=1.0/sum(session.values())\n",
    "        for artist in session:\n",
    "            if session[artist]*factor >= positive:\n",
    "                sample.append([user, artist, 1])\n",
    "        not_listened_artists = list(set(all_artist_ids) - set(session.keys()))\n",
    "        perc = int(len(not_listened_artists)*negative)\n",
    "        indices = random.sample(range(len(not_listened_artists)), perc)\n",
    "        for i in indices:\n",
    "            sample.append([user, not_listened_artists[i], -1])\n",
    "    return sample\n",
    "\n",
    "artists.reset_index(inplace = True)\n",
    "artist_ids = artists.ID.tolist() \n",
    "sample = create_sample(dictionary_data, artist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change f_name\n",
    "with open('metadata/sample_for_embed.pkl', 'wb') as f:\n",
    "    pickle.dump(sample, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't have GPU and I again used a piece of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "with open('metadata/sample_for_embed.pkl','rb') as f:\n",
    "    sample = pickle.load(f)\n",
    "\n",
    "sample = sample[:len(sample)//100]  \n",
    "print(len(sample)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoding ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users : 1427 unique artists: 8889\n"
     ]
    }
   ],
   "source": [
    "sample = np.asarray(sample)\n",
    "idx_2_user = dict(enumerate(set(sample[:, 0])))\n",
    "user_2_idx = {value:key for key,value in idx_2_user.items()}\n",
    "idx_2_artist = dict(enumerate(set(sample[:, 1])))\n",
    "artist_2_idx = {value:key for key,value in idx_2_artist.items()}\n",
    "\n",
    "a = np.array([user_2_idx[user] for user in sample[:, 0]])\n",
    "b = np.array([artist_2_idx[artist] for artist in sample[:, 1]])\n",
    "sample[:, 0] = a\n",
    "sample[:, 1] = b\n",
    "\n",
    "print('unique users :', len(idx_2_user), 'unique artists:', len(idx_2_artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(sample[:, :2]).to(torch.int64)\n",
    "y = torch.Tensor(sample[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.positive_samples_idx = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Select sample\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return X, y\n",
    "    \n",
    "    def get_posisve_samples_idx(self):\n",
    "        for i, y in enumerate(self.y):\n",
    "            if y:\n",
    "                self.positive_samples_idx.append(i)\n",
    "        return self.positive_samples_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train validation test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, batch_size, val_split_size = .15, test_split_size = .15):\n",
    "    \n",
    "    data_size = dataset.__len__()\n",
    "    positive_idx = dataset.get_posisve_samples_idx()\n",
    "    indices = list(range(data_size))\n",
    "    positive_data_size = len(positive_idx)\n",
    "    \n",
    "    val_split = int(np.floor(val_split_size * positive_data_size))\n",
    "    test_split = int(np.floor((test_split_size + val_split_size) * positive_data_size))\n",
    "\n",
    "    np.random.shuffle(positive_idx)\n",
    "    \n",
    "    val_indices = positive_idx[:val_split]\n",
    "    test_indices = positive_idx[val_split:test_split]\n",
    "    train_indices = positive_idx[test_split:] + list(set(indices) - set(positive_idx))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "\n",
    "    return train_loader, train_indices, val_indices, test_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model\n",
    "\n",
    "There was no time to add extra data to the dataset, but this code easily allows to do it.\n",
    "\n",
    "The models UserEmbedder and ArtistEmbedder are identical and have 2 torch.nn.Linear layers.\n",
    "\n",
    "*The main idea is to train and then calculate loss as nn.CosineEmbeddingLoss() between artist and user embeddings. The target value is {-1, 1}, as the range of cosine similarity values. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEmbedder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_hidden, users_size, embedding_dim, user_extra=0):\n",
    "        super(UserEmbedder, self).__init__()\n",
    "        self.user_embeddings = torch.nn.Embedding(users_size, embedding_dim)\n",
    "\n",
    "        self.user_extra = user_extra\n",
    "        last_hidden_input = embedding_dim\n",
    "\n",
    "        if user_extra:\n",
    "            last_hidden_input += self.user_extra\n",
    "\n",
    "        self.user_model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(last_hidden_input, n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(n_hidden, n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        user = self.user_embeddings(X)\n",
    "\n",
    "        # If user content features are available\n",
    "        if self.user_extra:\n",
    "            user = torch.cat([user, X['user_extra']], dim=1)\n",
    "\n",
    "        user = self.user_model(user)\n",
    "        return user\n",
    "\n",
    "\n",
    "class ArtistEmbedder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden, artist_size, embedding_dim, artist_extra=0):\n",
    "        super(ArtistEmbedder, self).__init__()\n",
    "        self.artist_embeddings = torch.nn.Embedding(artist_size, embedding_dim)\n",
    "\n",
    "        last_hidden_input = embedding_dim\n",
    "        self.artist_extra = artist_extra\n",
    "\n",
    "        if artist_extra:\n",
    "            last_hidden_input += self.artist_extra\n",
    "\n",
    "        self.artist_model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(last_hidden_input, n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(n_hidden, n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        artist = self.artist_embeddings(X)\n",
    "\n",
    "        # If artist content features are available\n",
    "        if self.artist_extra:\n",
    "            artist = torch.cat([artist, X['artist_extra']], dim=1) \n",
    "\n",
    "        artist = self.artist_model(artist)\n",
    "        return artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting numpy array to dictionary\n",
    "\n",
    "def array_to_dict(array):\n",
    "    d = defaultdict(list)\n",
    "    for i in array:\n",
    "        d[int(i[0])].append(int(i[1]))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(X, y)\n",
    "train_loader, train_ind, val_ind, test_ind = split_data(dataset, batch_size = 256)\n",
    "\n",
    "# moving to dictionaries to accelerate access to the data\n",
    "\n",
    "X_val = array_to_dict(X[val_ind])\n",
    "X_test = array_to_dict(X[test_ind])\n",
    "X_train = array_to_dict(X[train_ind])\n",
    "\n",
    "val_unique_users = len(X_val)\n",
    "test_unique_users = len(X_test)\n",
    "\n",
    "n_hidden = 20\n",
    "users_size = len(idx_2_user)\n",
    "\n",
    "# to capture more information it's better to use bigger dim (for ex. 50)\n",
    "# I'd icrease the embedding_dim if had a better machine\n",
    "\n",
    "embedding_dim = 10 \n",
    "artist_size = len(idx_2_artist)\n",
    "\n",
    "userEmbedder = UserEmbedder(n_hidden, users_size, embedding_dim)\n",
    "userEmbedder.type(torch.FloatTensor)\n",
    "\n",
    "artistEmbedder = ArtistEmbedder(n_hidden, artist_size, embedding_dim)\n",
    "artistEmbedder.type(torch.FloatTensor)\n",
    "\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = optim.Adam(list(userEmbedder.parameters()) + list(artistEmbedder.parameters()), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation function\n",
    "\n",
    "For each user in the validation set we recommend topk **new** artists. Then we check how many of the recomendations are relevant to the user. The goal is to recommend artists_ids from the validation dataset.\n",
    "\n",
    "The result for each user is the **n_relevant_recomendations/min(topk, n_relevant)**. min(topk, n_relevant) is needed in case if there will be more than k relevant artists in the validation dataset.\n",
    "\n",
    "The result of the function is the average of the results for the users. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(all_user_embed, all_artist_embed, X_val, X, n_unique_users, k = 10, batch_size = 1000):\n",
    "    \"\"\"\n",
    "        Validate the model\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "        all_user_embed, all_artist_embed - embeddings for all users and all artists\n",
    "        X_val - dictionary with validation samples. X_val = {user_id: [arist_id_1, ..., arist_id_k]}\n",
    "        X - dictionary with train samples. X = {user_id: [arist_id_1, ..., arist_id_k]}.\n",
    "        X is used to get the artists, that the user has already listened - we want to recommend only new artists. \n",
    "        n_unique_users - number of unique users in the validation set\n",
    "        k - looking for relevant artists only in top k recomendations\n",
    "        batch_size - batch_size for artist embedding\n",
    "    \"\"\"\n",
    "    cosine = torch.nn.CosineSimilarity()\n",
    "    artists_embed_sampler = SubsetRandomSampler(list(range(all_artist_embed.shape[0])))\n",
    "    embed_loader = torch.utils.data.DataLoader(all_artist_embed, batch_size=batch_size,\n",
    "                                         sampler=artists_embed_sampler)\n",
    "    total_relevant = 0\n",
    "    for user_id, artists in X_val.items():\n",
    "        \n",
    "        relevant_artists = np.array(artists)\n",
    "        listened_artists = np.array(X[user_id])\n",
    "        \n",
    "        topk = torch.Tensor()\n",
    "        topk_indices = torch.Tensor()\n",
    "        current_user_tensor = all_user_embed[user_id].view(1, all_user_embed.shape[1])\n",
    "        \n",
    "        # calculate cosine similarity in batches\n",
    "        for batch_artist in embed_loader:\n",
    "            cos_dist = cosine(current_user_tensor, batch_artist)\n",
    "            topk_b, topk_indices_b = torch.sort(cos_dist, descending = True)\n",
    "            topk = torch.cat([topk, topk_b[:k]], dim=0)\n",
    "            topk_indices = torch.cat([topk_indices, topk_indices_b[:k].type(torch.FloatTensor)], dim=0)\n",
    "        \n",
    "        topk_all = np.transpose(torch.stack([topk, topk_indices], dim=0).detach().numpy())\n",
    "        topk_all = topk_all[topk_all[:,0].argsort()]\n",
    "        topk_indices = topk_all[:, 1]\n",
    "        \n",
    "        # deleting listened_artists\n",
    "        topk_artists_recommendation = np.setdiff1d(topk_indices, listened_artists, assume_unique = True)[:k]\n",
    "        n_relevant = len(relevant_artists)\n",
    "        \n",
    "        # looking for intersection in topk recomendations and relevant artists\n",
    "        n_relevant_recommendations = np.intersect1d(relevant_artists, topk_artists_recommendation).shape[0]/min(k, n_relevant)\n",
    "        total_relevant += n_relevant_recommendations\n",
    "        \n",
    "    return total_relevant/n_unique_users \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning\n",
    "\n",
    "The model was trained for 2K epochs and the model with the best validation score was chosen.\n",
    "\n",
    "The score would increase dramatically if it would be possible to use GPU, increase sample size, and embeddings dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "import copy\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "num_epochs = 2000\n",
    "best_val_metric = 0\n",
    "cosine = torch.nn.CosineSimilarity()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    userEmbedder.train()\n",
    "    artistEmbedder.train()\n",
    "    loss_accum = 0\n",
    "    user_emb_full = torch.Tensor()\n",
    "    artist_emb_full = torch.Tensor()\n",
    "    for i_step, (x, target) in enumerate(train_loader):\n",
    "        \n",
    "        user_emb = userEmbedder.forward(x[:, 0])\n",
    "        artist_emb = artistEmbedder.forward(x[:, -1])\n",
    "        loss = criterion(user_emb, artist_emb, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_accum += loss\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "    ave_loss = loss_accum / i_step\n",
    "     \n",
    "        \n",
    "    # Validating every 20 epochs and saving the best model\n",
    "    if (epoch % 20) == 0:\n",
    "        all_user_embed = userEmbedder.forward(torch.Tensor([x for x in range(len(idx_2_user))]).to(torch.int64))\n",
    "        all_artist_embed = artistEmbedder.forward(torch.Tensor([x for x in range(len(idx_2_artist))]).to(torch.int64))\n",
    "        metric = validate(all_user_embed, all_artist_embed, X_val, X_train, val_unique_users)\n",
    "        if metric > best_val_metric:\n",
    "            best_val_metric = metric\n",
    "            best_user_emb = copy.deepcopy(userEmbedder)\n",
    "            best_artist_emb = copy.deepcopy(artistEmbedder)\n",
    "        print('metric: %f' % metric)\n",
    "\n",
    "    print(\"epoch %d, loss: %f\" % (epoch, ave_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open(r\"metadata/best_user_emb.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(best_user_emb, output_file)\n",
    "    \n",
    "with open(r\"metadata/best_artist_emb.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(best_artist_emb, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(r\"metadata/best_user_emb.pkl\",'rb') as f:\n",
    "    best_user_emb = pickle.load(f)\n",
    "\n",
    "with open(r\"metadata/best_artist_emb.pkl\",'rb') as f:\n",
    "    best_artist_emb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003218884120171674"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_user_embedings = best_user_emb.forward(torch.Tensor([x for x in range(len(idx_2_user))]).to(torch.int64))\n",
    "best_artist_embedings = best_artist_emb.forward(torch.Tensor([x for x in range(len(idx_2_artist))]).to(torch.int64))\n",
    "res = validate(best_user_embedings, best_artist_embedings, X_test, X_train, test_unique_users)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Soul+of+Chill',\n",
       " 'Johnny+Depp,+Alan+Rickman',\n",
       " 'Original+Evita+Cast',\n",
       " 'Jazz+4',\n",
       " 'Cervidae',\n",
       " 'Cieplarnia',\n",
       " 'Guillaume+Roussel',\n",
       " 'Mob+Serenade',\n",
       " 'James+Brown+&+Luciano+Pavarotti',\n",
       " 'Heib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_to_user(user, user_emb, artist_emb, X, artists, k = 10):\n",
    "    recommendation_names = []\n",
    "    recommendation_ids = []\n",
    "    user_idx = user_2_idx[user]\n",
    "    cosine = torch.nn.CosineSimilarity()\n",
    "    all_user_embed = user_emb.forward(torch.Tensor([x for x in range(len(idx_2_user))]).to(torch.int64))\n",
    "    all_artist_embed = artist_emb.forward(torch.Tensor([x for x in range(len(idx_2_artist))]).to(torch.int64))\n",
    "    \n",
    "    listened_artists = np.array(X[user_idx])\n",
    "        \n",
    "    cos_dist = cosine(all_user_embed[user_idx].view(1,all_user_embed.shape[1]), all_artist_embed)\n",
    "    topk, topk_indices = torch.sort(cos_dist, descending = True)\n",
    "    topk_artists_recommendation = np.setdiff1d(topk_indices, listened_artists, assume_unique = True)[:k]\n",
    "    \n",
    "    for idx in topk_artists_recommendation:\n",
    "        artist_id = idx_2_artist[idx]\n",
    "        recommendation_names.append(artists[artists.ID == artist_id].reset_index().at[0, 'Name'])\n",
    "        recommendation_ids.append(artist_id)\n",
    "    return recommendation_ids, recommendation_names\n",
    " \n",
    "user_id = 4    \n",
    "idx, names = recommend_to_user(user_id, best_user_emb, best_artist_emb, X, artists)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sixteen+Horsepower:  ['Loft+Apartment', 'Topol+and+Original+Broadway+Cast', 'Nas+feat.+Anthony+Hamilton', 'Shell+Shocked', 'Boi+Akih', 'SunSuch', '%D0%9D%D0%B8%D0%BA%D0%BE%D0%BB%D0%B0%D0%B9+%D0%91%D0%B0%D1%81%D0%BA%D0%BE%D0%B2', 'Lycia%2FMike+Van+Portfleet', 'AVT', 'Redneck+surfers']\n",
      "Pink+Floyd+&+Floyd:  ['Flexi+Cowboys', 'Damon+Dash', 'Music+City+Singers', 'Eu+gosto+tanto+de+voc%C3%AA', 'The+Pietro+Carapellucci+Choir', 'KC+and+The+Sunshine+Band', 'Matricians', 'Hill+Briggs', 'Seven+Nails', 'The+Royal+Concept']\n"
     ]
    }
   ],
   "source": [
    "def find_topk_similar_artists(artist, artist_emb, artists, k = 10):\n",
    "    topk_names = []\n",
    "    topk_ids = []\n",
    "    artist_idx = artist_2_idx[artist]\n",
    "    cosine = torch.nn.CosineSimilarity()\n",
    "        \n",
    "    cos_dist = cosine(artist_emb[artist_idx].view(1, artist_emb.shape[1]), artist_emb)\n",
    "    topk, topk_indices = torch.sort(cos_dist, descending = True)\n",
    "    topk_artists = np.setdiff1d(topk_indices, np.array(artist_idx), assume_unique = True)[:k]\n",
    "    \n",
    "    for idx in topk_artists:\n",
    "        artist_id = idx_2_artist[idx]\n",
    "        topk_names.append(artists[artists.ID == artist_id].reset_index().at[0, 'Name'])\n",
    "        topk_ids.append(artist_id)\n",
    "    return topk_ids, topk_names\n",
    "\n",
    "# arist_id = 1756 artist_name = Sixteen+Horsepower\n",
    "# arist_id = 4101 artist_name = Pink+Floyd+&+Floyd \n",
    "\n",
    "_, names = find_topk_similar_artists(1756, best_artist_embedings, artists)\n",
    "print('Sixteen+Horsepower: ', names)\n",
    "\n",
    "_, names = find_topk_similar_artists(276125, best_artist_embedings, artists)\n",
    "print('Pink+Floyd+&+Floyd: ', names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "As you can see the test doesn't show great results, but this model has a lot of potentials. To improve it we should add extra information about users and artists, increase the sample size and embedding dimension. Also, increase the number of epochs.\n",
    "\n",
    "This project also shows that often a simple solution is preferable to a complicated one, especialy if there are not enough computational resources and data. (Of course, it is not the case for industry tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model samples for t-test\n",
    "X_test_keys = [i for i in X_test.keys()]\n",
    "n_users = test_unique_users//10\n",
    "test_samples = [sample(X_test_keys, n_users) for i in range(30)]\n",
    "\n",
    "Embed_model_sample = []\n",
    "for X_test_key_sample in test_samples:\n",
    "    X_test_sample = {key: X_test[key] for key in X_test_key_sample}\n",
    "    print(X_test_sample)\n",
    "    res = validate(best_user_embedings, best_artist_embedings, X_test_sample, X_train, n_users)\n",
    "    Embed_model_sample.append(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical two-sided t-test\n",
    "Hypothesis:\n",
    "\n",
    "* H0: Samples have identical average\n",
    "* H1: Samples have different averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 mean value: 0.0013593380614657208\n",
      "model2 mean value: 0.005977011494252874 \n",
      "\n",
      "model1 std value: 0.002990917477276594\n",
      "model2 std value: 0.005833828754229665\n",
      "\n",
      "\n",
      "p-value 0.0003571489452935831\n",
      "we reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def compare_samples_t_test(s1, s2):\n",
    "    m1_mean = np.mean(s1)\n",
    "    m2_mean = np.mean(s2)\n",
    "    print(\"model1 mean value:\",m1_mean)\n",
    "    print(\"model2 mean value:\",m2_mean, '\\n')\n",
    "    m1_std = np.std(s1)\n",
    "    m2_std = np.std(s2)\n",
    "    print(\"model1 std value:\", m1_std)\n",
    "    print(\"model2 std value:\", m2_std)\n",
    "    print('\\n')\n",
    "    ttest,pval = ttest_ind(s1, s2)\n",
    "    print(\"p-value\",pval)\n",
    "    if pval < 0.05:\n",
    "        print(\"we reject null hypothesis\")\n",
    "    else:\n",
    "        print(\"we accept null hypothesis\")\n",
    "        \n",
    "compare_samples_t_test(Embed_model_sample, CF_model_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
